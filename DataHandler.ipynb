{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Polish Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "TODAY = datetime.date.today()\n",
    "CURRENT_YEAR = TODAY.year\n",
    "DEFAULT_LAT = \"52.2337172\" # points to Warsaw, Poland\n",
    "DEFAULT_LON = \"21.0714322\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finds Processor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes dates are written as XX' of XXth c.; converts these expressions to yyyy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCentury(date):\n",
    "    match = re.search(r\"st|nd|th\", date) # date is in century form\n",
    "    if (match):\n",
    "        half = re.split(\"of\", date)\n",
    "\n",
    "        subCenturyText = re.search(r\"[0-9][0-9]|[0-9]\", half[0])\n",
    "        subCenturyInt = int(subCenturyText.group()) # this is the last 2 digits of yyyy\n",
    "\n",
    "        centuryText = re.search(r\"[0-9][0-9]|[0-9]\", half[1])\n",
    "        centuryInt = int(centuryText.group()) # the century, e.g. 20th century\n",
    "\n",
    "        year = ((centuryInt - 1) * 100) + subCenturyInt\n",
    "        start = subCenturyText.start()\n",
    "        end = subCenturyText.end() + centuryText.end() + 8\n",
    "        date = half[0] + half[1]\n",
    "        date = date[:start] + str(year) + date[end:]\n",
    "        return date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below parses for year found. Some variation in input causes complexity here; for example, here are some inputs:\n",
    "<br>\n",
    "before Oct.2010\n",
    "<br>\n",
    "bef. 1960\n",
    "<br>\n",
    "2005 or earlier\n",
    "<br>\n",
    "around 1930\n",
    "<br>\n",
    "06 and 11.2006\n",
    "<br>\n",
    "1.11.1865\n",
    "<br>\n",
    "c. 1900-1914\n",
    "<br>\n",
    "1880s\n",
    "<br>\n",
    "21 June 1875\n",
    "<br>\n",
    "Spring 1962\n",
    "<br>\n",
    "1926/27\n",
    "<br>\n",
    "1872 or 1875\n",
    "<br>\n",
    "Therefore, new cases may need to be covered if new variations arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(find: dict, date):\n",
    "    if (re.fullmatch(r\"([0-9][0-9][0-9][0-9])+$\", date)):  # string is simple, only 4 consecutive digits, e.g. '2003'\n",
    "        find[\"year_found\"] = date\n",
    "        find[\"year_found_end\"] = date\n",
    "        return\n",
    "# at this point, date can be complex. First make sure date is not in century format\n",
    "    if (re.search(r\"[0-9](st|nd|th)\", date)):\n",
    "        date = convertCentury(date) # if century format, convert it to yyyy\n",
    "        \n",
    "    year = re.search(r\"([0-9][0-9][0-9][0-9])\", date).group() # extracted year string\n",
    "    \n",
    "    if (re.search(r\"bef|earl|pre\", date)): # if end of range specified\n",
    "        find[\"year_found\"] = \"1700\"\n",
    "        find[\"year_found_end\"] = year\n",
    "        return\n",
    "    \n",
    "    if (re.search(r\"after|later|post\", date)): # if start of range specified\n",
    "        find[\"year_found\"] = year\n",
    "        find[\"year_found_end\"] = CURRENT_YEAR\n",
    "        return\n",
    "    \n",
    "    # if full range is specified (checking for 4 digits to eliminate '-' being used between days: 26-27 June, 2003)\n",
    "    if (re.search(r\"[1-2][0-9][0-9][0-9]\\s*(or|/|-|to|and)\", date) and not re.search(r\"ctober\", date)):\n",
    "        year = re.findall(r\"([0-9][0-9][0-9][0-9])\", date)\n",
    "        find[\"year_found\"] = year[0]\n",
    "        if (year.__len__() != 1): # if string looks like 1991-2003\n",
    "            find[\"year_found_end\"] = year[1]\n",
    "            return\n",
    "        else: # string looks like 1961-64\n",
    "            pattern = r\"or|/|-|to|and\"\n",
    "            endYear = year[0][:2] + re.search(r\"[0-9][0-9]\", re.split(pattern, date, 1)[1]).group()  # construct full end year: 64 -> 1964\n",
    "            if (int(endYear) < int(year[0])): endYear = str(int(endYear) + 100) # in case of 1997-01\n",
    "            find[\"year_found_end\"] = endYear\n",
    "            return\n",
    "\n",
    "    if (re.search(r\"[1-2][0-9][0-9]0s\", date)): # if decade range given, e.g. 1880s\n",
    "        year = re.search(r\"[1-2][0-9][0-9]\", date).group()\n",
    "        find[\"year_found\"] = year + \"0\"\n",
    "        find[\"year_found_end\"] = year + \"9\"\n",
    "        return\n",
    "    \n",
    "    # at this point no special markers (before, after, -, etc.) left, just take the year and ignore other characters\n",
    "    find[\"year_found\"] = year\n",
    "    find[\"year_found_end\"] = year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines if findSpotName contains a digit or Roman numeral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsNumber(place) -> bool:\n",
    "    pattern = re.compile(r\"[0-9]|(\\s(I|V|X|L|C)(?=(\\s|$|I|V|X|L|C)))\")\n",
    "    if (re.search(pattern, str(place))): \n",
    "        return True\n",
    "    else: return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determines what finds are single finds, hoards, and excavations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleOrHoard(freq, finds): \n",
    "    for find in finds:\n",
    "        place = find[\"Name\"]\n",
    "        year = find[\"tempYear\"]\n",
    "        if (len(freq[(place, year)]) > 1 and containsNumber(place)): # then it's part of a hoard.\n",
    "            find[\"type_find\"] = \"Hoard\"\n",
    "            find[\"num_coins\"] = len(freq[(place, year)])\n",
    "            find[\"hoard?\"] = True\n",
    "            find[\"single?\"] = False\n",
    "            duplicates = freq[(place, year)]\n",
    "            index = 1 # to keep the 0th one from being removed\n",
    "            representativeEntry = duplicates[0] # the 0th one\n",
    "            while (index < len(freq[(place, year)])):\n",
    "                duplicate = duplicates[index]\n",
    "\n",
    "                if (int(duplicate[\"find_start_date\"] < int(representativeEntry[\"find_start_date\"]))):\n",
    "                    representativeEntry[\"find_start_date\"] = duplicate[\"find_start_date\"]\n",
    "                \n",
    "                if (int(duplicate[\"find_end_date\"]) > int(representativeEntry[\"find_end_date\"])):\n",
    "                    representativeEntry[\"find_end_date\"] = duplicate[\"find_end_date\"]\n",
    "                \n",
    "                groupToFind[duplicate[\"FindNumber\"]] = representativeEntry[\"FindNumber\"] # to later map groups to the correct find id.\n",
    "                finds.remove(duplicate)\n",
    "                index += 1\n",
    "        else: \n",
    "            find[\"type_find\"] = \"Single Find\"\n",
    "            find[\"num_coins\"] = 1\n",
    "            find[\"hoard?\"] = False\n",
    "            find[\"single?\"] = True\n",
    "        find[\"excavation?\"] = bool(re.search(r\"excav\", str(find[\"tempCircumstances\"]), re.IGNORECASE)) # check for \"excav\" in findCircumstance\n",
    "        find.pop(\"tempYear\") # don't need these anymore\n",
    "        find.pop(\"tempCircumstances\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up dataframe as a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "finds = list()\n",
    "freq = defaultdict(list)\n",
    "singleFinds = defaultdict(list)\n",
    "find_id_to_Index = {}\n",
    "years = {}\n",
    "path = \"C:/Users/there/Documents/Code/Numismatics/AFE PL 325-750 (Polish Data).xlsx\"\n",
    "theirData = pd.read_excel(path)\n",
    "for index, row in theirData.iterrows():\n",
    "    find = {}\n",
    "    find[\"FindNumber\"] = row[\"ID\"]\n",
    "    find[\"Name\"] = row[\"FindspotName\"]\n",
    "    place = find[\"Name\"]\n",
    "    year = row[\"YearFound\"]\n",
    "\n",
    "    freq[(place, year)].append(find)\n",
    "\n",
    "    find[\"lat\"] = row[\"LatitudePlace\"]\n",
    "    find[\"long\"] = row[\"LongitudePlace\"]\n",
    "    find[\"cf_custom_region_vague\"] = 2\n",
    "    if (pd.isnull(find[\"lat\"]) or pd.isnull(find[\"long\"])): # if 1st set of coords not available, check next set in next 2 cells\n",
    "        find[\"lat\"] = row[\"LatitudeFS\"]\n",
    "        find[\"long\"] = row[\"LatitudeFS_1\"]\n",
    "        if (pd.isnull(find[\"lat\"]) or pd.isnull(find[\"long\"])): # if still null, use default\n",
    "            find[\"lat\"] = DEFAULT_LAT\n",
    "            find[\"long\"] = DEFAULT_LON\n",
    "            find[\"cf_custom_region_vague\"] = 0\n",
    "    \n",
    "    find[\"find_start_date\"] = row[\"DateFrom\"]\n",
    "    find[\"find_end_date\"] = row[\"DateTo\"]\n",
    "\n",
    "    find[\"tempYear\"] = row[\"YearFound\"] # temporary, for use in singleOrHoard function\n",
    "    find[\"tempCircumstances\"] = row[\"Findcircumstances\"] # Same as above\n",
    "\n",
    "    try:get_date(find, row[\"YearFound\"])\n",
    "    except: # when YearFound is \"\" or \"no data\"\n",
    "        find[\"year_found\"] = \"1700\"\n",
    "        find[\"year_found_end\"] = CURRENT_YEAR\n",
    "    \n",
    "    find[\"comments\"] = row[\"Findcircumstances\"]\n",
    "    find[\"imported\"] = TODAY\n",
    "    find[\"references\"] = row[\"Bibliography\"]\n",
    "    find[\"owner\"] = \"FRC-PL\"\n",
    "    find[\"created\"] = TODAY\n",
    "    finds.append(find)\n",
    "singleOrHoard(freq, finds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each id to its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "for find in finds:\n",
    "    find_id_to_Index[find[\"FindNumber\"]] = index\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine duplicate single coin finds to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives = defaultdict(list)\n",
    "toRemove = list()\n",
    "for find in finds:\n",
    "    if (find[\"type_find\"] == \"Single Find\"):\n",
    "        values =  (\n",
    "                  find[\"Name\"], find[\"lat\"], find[\"long\"], find[\"cf_custom_region_vague\"], find[\"find_start_date\"], \n",
    "                  find[\"find_end_date\"], find[\"year_found\"], find[\"year_found_end\"]\n",
    "                  )\n",
    "        rep = representatives.get(values)\n",
    "        if (rep == None): # coin not found yet, so it now represents any future coins that have the same values\n",
    "            representatives[values] = find\n",
    "        else: # coin already has a representative\n",
    "            rep[\"num_coins\"] += 1\n",
    "            toRemove.append(find)\n",
    "for duplicate in toRemove:\n",
    "    finds.remove(duplicate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MINT = \"Unknown (Roman Empire)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMetal(symbol): # convert metal symbol\n",
    "    metal_conversion = {\n",
    "        'Ae': 'bronze', \n",
    "        'Ag': 'silver', \n",
    "        'Au': 'gold'\n",
    "    }\n",
    "    return metal_conversion.get(symbol, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDenomination(denomination): # Taken from Mark's AFE code\n",
    "    denomination_conversion = {\n",
    "    'Denarius':'denarius', 'Semis':'semissis', 'AE1': 'AE1 (8.05g)',\n",
    "        'AE2 / AE3': 'AE2 (5.15g) or AE3 (2.58g)', 'AE3 / AE2': 'AE3 (2.58g) or AE2 (5.15g)',\n",
    "            'AE3 / AE4': 'AE3 (2.58g) or AE4 (1.23g)', 'AE4 / AE3': 'AE4 (1.23g) or AE3 (2.58g)',\n",
    "                'Aureus':'aureus', 'AE':'uncertain (bronze)', 'Antoninianus':'radiate or nummus (UK find)',\n",
    "                    'Follis':'follis','AE2':'AE2 (5.15g)', 'Drachme':'drachm', 'AV':'AV', 'Maiorina':'follis',\n",
    "                'AE3':'AE3 (2.58g)', 'Solidus':'solidus', 'Silber':'uncertain (silver)', 'Siliqua':'siliqua', \n",
    "            'AE4':'AE4 (1.23g)', 'Tremissis':'tremissis', '10 Num' : '10 nummi', '2 Solidi' : '2 solidi', \n",
    "         'Miliarensis' : 'miliarensis', 'Argenteus': 'argenteus', 'Bronze': 'uncertain (bronze)',\n",
    "    'Solidus / Tremissis': 'solidus or tremissis', 'Siliqua (reduziert)' : 'reduced siliqua',\n",
    "    }\n",
    "    return denomination_conversion.get(denomination, \"uncertain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMint(mint): # converting mints into FLAME format\n",
    "    # Thanks for this Mark!\n",
    "    mint_conversion = {\n",
    "    'Roma':'Roma', 'Alexandria':'Alexandria ad Aegyptum', 'Uncertain mint':'Unknown', 'Constantinopolis':'Constantinople',\n",
    "       'Unofficial mint':'Unknown', 'Siscia':'Siscia', 'Thessalonica':'Thessalonika', \n",
    "       'Thessalonica / Treveri': 'Thessalonika or Colonia Augusta Treverorum', 'Roma / Treveri': 'Roma or Colonia Augusta Treverorum',\n",
    "       'Treveri / Siscia': 'Colonia Augusta Treverorum or Siscia', 'Londinium':'Londinium', \n",
    "    'Treveri / Constantinopolis': 'Colonia Augusta Treverorum or Constantinople', 'Treveri':'Colonia Augusta Treverorum', \n",
    "       'Lugdunum':'Lugdunensium', 'Ticinum':'Ticinum', 'Aquileia':'Aquileia', 'Colonia CAA':'Unknown', 'Antiochia':'Antioch', \n",
    "       'Emerita':'Emerita', 'Lycia':'Unknown (East Roman)', 'Cyzicus':'Kyzikos', 'Roma / Lugdunum':'Roma or Lugdunum',\n",
    "        'Sirmium':'Sirmium', 'Eastern mint':'Unknown (East Roman)', 'Gallia':'Unknown (Gaul)', 'Unidentified mint':'Unknown',\n",
    "    'Laodicea ad Mare':'Laodicea ad Mare', 'Mediolanum':'Mediolanum', 'Constantinopolis / Mediolanum': 'Constantinople or Mediolanum', \n",
    "        'Ravenna':'Ravenna', 'Roma / Tarraco (?)':'Roma or Tarracona', 'Africa':'Unknown (Africa)', 'Hispania':'Unknown (Iberia)', \n",
    "        'Colonia Caesaraugusta':'Cesaraugusta', 'Greek East':'Unknown (East Roman)', 'Münzstätte nicht bekannt':'Unknown (Germany)', \n",
    "        'Östliche Münzstätte' : 'Unknown (Germany)', 'Sicilia' : 'Sicily', 'Syrien' : 'Unknown (Greater Syria)',\n",
    "    'Arelate' : 'Arelato', 'Heracleia' : 'Heraclea', 'Nicomedia': 'Nicomedia'\n",
    "    }\n",
    "    return mint_conversion.get(mint, DEFAULT_MINT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines duplicates and assigns num_coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNums(groups):\n",
    "    for group in groups:\n",
    "        if (len(duplicates[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])]) > 1):\n",
    "            dupes = duplicates[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])]\n",
    "            index = 1 # to keep 0th one from being removed\n",
    "            while (index < len(duplicates[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])])):\n",
    "                 groups.remove(dupes[index])\n",
    "                 index += 1\n",
    "            group[\"num_coins\"] = len(duplicates[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up groups dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = list()\n",
    "duplicates = defaultdict(list)\n",
    "for index, row in theirData.iterrows():\n",
    "    group = {}\n",
    "    group[\"group_index\"] = index + 1\n",
    "    group[\"name\"] = row[\"FindspotName\"]\n",
    "    group[\"frcpl_find_id\"] = groupToFind.get(row[\"ID\"], row[\"ID\"]) # if not found, default to row[\"ID\"]\n",
    "    group[\"mint\"] = convertMint(row[\"Mint\"])\n",
    "\n",
    "    group[\"denomination\"] = convertDenomination(row[\"Denomination\"])\n",
    "\n",
    "    group[\"start_year\"] = row[\"DateFrom\"]\n",
    "    group[\"end_year\"] = row[\"DateTo\"]\n",
    "\n",
    "    ruler = row[\"Issuer\"]\n",
    "    if (ruler != ruler): # sometimes nan, leaving blank cell\n",
    "        group[\"ruler\"] = \"Uncertain\"\n",
    "    else:\n",
    "        group[\"ruler\"] = ruler\n",
    "    \n",
    "    group[\"num_coins\"] = 1\n",
    "\n",
    "    id_of_original_find = group[\"frcpl_find_id\"]\n",
    "    index_of_original_find = find_id_to_Index[id_of_original_find]\n",
    "    group[\"coin_find_index\"] = \"FRCPL-\" + str(index_of_original_find)\n",
    "\n",
    "    group[\"created\"] = TODAY\n",
    "    group[\"imported\"] = TODAY\n",
    "    group[\"owner\"] = \"FRCPL\"\n",
    "    group[\"comments\"] = row[\"Findcircumstances\"]\n",
    "    group[\"metal\"] = convertMetal(row[\"Material\"])\n",
    "\n",
    "    if (group[\"denomination\"] == \"Unknown\" or group[\"denomination\"] == \"unknown\" or group[\"denomination\"] == \"uncertain\" \n",
    "        and group[\"metal\"] != \"Unknown\"):\n",
    "        group[\"denomination\"] += \" (\" + group[\"metal\"] + \")\"\n",
    "\n",
    "    duplicates[(group[\"name\"], group[\"denomination\"], group[\"start_year\"], group[\"end_year\"], group[\"mint\"])].append(group)\n",
    "    groups.append(group)\n",
    "getNums(groups) # combines duplicates and assigns num_coins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add FRCPL-X-X indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups[0][\"coin_find_group_index\"] = \"FRCPL-1-1\"\n",
    "index = 0\n",
    "group_index = 1\n",
    "for group in groups:\n",
    "    if (groups[index-1][\"coin_find_index\"] == group[\"coin_find_index\"]): # if still part of the same find\n",
    "        group_index += 1\n",
    "    else:\n",
    "        group_index = 1\n",
    "    group[\"coin_find_group_index\"] = group[\"coin_find_index\"] + \"-\" + str(group_index)\n",
    "    index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export finds to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(finds)\n",
    "type = df.pop(\"type_find\") # rearranging two columns\n",
    "num = df.pop(\"num_coins\")\n",
    "df.insert(2, \"type_find\", type)\n",
    "df.insert(5, \"num_coins\", num)\n",
    "df.index += 1\n",
    "df.to_csv(\"final_frcpl_finds.csv\", encoding='utf16', sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export groups to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(groups)\n",
    "find_index = df2.pop(\"coin_find_index\")\n",
    "find_group_index = df2.pop(\"coin_find_group_index\")\n",
    "df2.insert(1, \"coin_find_index\", find_index)\n",
    "df2.insert(2, \"coin_find_group_index\", find_group_index)\n",
    "df2.index += 1\n",
    "df2.to_csv(\"final_frcpl_groups.csv\", encoding='utf16', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
